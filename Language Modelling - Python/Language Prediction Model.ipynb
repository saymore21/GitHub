{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV RESULTS:\n",
      "\n",
      "\n",
      "*English-French : \n",
      "-----------------------------------------------------------------------\n",
      "Accuracy for Unigram Model: 70.58823529411765\n",
      "Accuracy for Bigram Model: 94.11764705882354\n",
      "Accuracy for Trigram Model: 100.0\n",
      "\n",
      "\n",
      "*Spanish-Italian : \n",
      "-----------------------------------------------------------------------\n",
      "Accuracy for Unigram Model: 64.70588235294117\n",
      "Accuracy for Bigram Model: 76.47058823529412\n",
      "Accuracy for Trigram Model: 94.11764705882354\n",
      "\n",
      "\n",
      "************************************************************************\n",
      "\n",
      "\n",
      "TEST OUTPUT:\n",
      "\n",
      "\n",
      "*English-French : \n",
      "-----------------------------------------------------------------------\n",
      "Accuracy for Unigram Model: 78.2\n",
      "Accuracy for Bigram Model: 92.1\n",
      "Accuracy for Trigram Model: 99.0\n",
      "\n",
      "\n",
      "*Spanish-Italian : \n",
      "-----------------------------------------------------------------------\n",
      "Accuracy for Unigram Model: 67.0\n",
      "Accuracy for Bigram Model: 84.6\n",
      "Accuracy for Trigram Model: 96.3\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import udhr\n",
    "from nltk.util import ngrams\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "\n",
    "\n",
    "def data_preprocess(text):\n",
    "    text = str.lower(text.translate(str.maketrans('','',string.punctuation)).strip())\n",
    "    text = re.sub('\\n',' ', text) \n",
    "    return text\n",
    "\n",
    "#calulate probabilty distribution from frequency distribution\n",
    "def find_probablity(freq_dist):\n",
    "    total_count = 0\n",
    "    for key in freq_dist:\n",
    "        total_count = total_count + freq_dist[key]\n",
    "    probablity_dict = {}\n",
    "    for key in freq_dist:\n",
    "        probablity_dict[key] = freq_dist[key]/total_count\n",
    "    return probablity_dict\n",
    "\n",
    "#Function to calculate the probablity of Unigram model\n",
    "def Find_Unigram_Prob(data, Lang):\n",
    "    count = 1\n",
    "    uni_data = Uni_Probability[Lang]\n",
    "    for ch in data:\n",
    "        key = (ch,)\n",
    "        count_no_of_key = uni_data[key] if key in uni_data else 0\n",
    "        \n",
    "        if count_no_of_key == 0:\n",
    "            return 0\n",
    "        \n",
    "        count  = count * count_no_of_key\n",
    "        \n",
    "    return count\n",
    "\n",
    "#Function to calculate the probablity of Bi model\n",
    "def Find_Bigram_Prob(data, Lang):\n",
    "    data_len = len(data)    \n",
    "    if data_len < 2:\n",
    "        return Find_Unigram_Prob(data, Lang)\n",
    "    \n",
    "    count = 1\n",
    "    bi_data = Bi_Probability[Lang]\n",
    "    \n",
    "    for i in range(data_len+1):\n",
    "        if i == 0:\n",
    "            key = (' ',data[i])\n",
    "        elif i == data_len:\n",
    "            key == (data[i-1], ' ')\n",
    "        else:\n",
    "            key = (data[i-1],data[i])\n",
    "        \n",
    "        count_no_of_key = bi_data[key] if key in bi_data else 0\n",
    "        \n",
    "        if count_no_of_key == 0:\n",
    "            return 0\n",
    "        \n",
    "        prev_char = ' ' if i == 0 else data[i-1]\n",
    "        \n",
    "        count = count * count_no_of_key / Find_Unigram_Prob(str(prev_char), Lang)\n",
    "    \n",
    "    return count;\n",
    "\n",
    "#Function to calculate the probablity of trigram model\n",
    "def Find_Trigram_Prob(data, Lang):\n",
    "    data_len = len(data)\n",
    "    if data_len < 3:\n",
    "        return Find_Bigram_Prob(data, Lang)\n",
    "    \n",
    "    count = 1\n",
    "    tri_data = Tri_Probability[Lang]\n",
    "    \n",
    "    for i in range(1, data_len+1):\n",
    "        if i == 1:\n",
    "            key = (' ', data[i-1], data[i])\n",
    "        elif i == data_len:\n",
    "            key = (data[i-2], data[i-1], ' ')\n",
    "        else:\n",
    "            key = (data[i-2], data[i-1], data[i])\n",
    "        \n",
    "        count_no_of_key = tri_data[key] if key in tri_data else 0\n",
    "        \n",
    "        if count_no_of_key == 0:\n",
    "            return 0\n",
    "        \n",
    "        new_key = (' ', data[i-1]) if i == 1 else (data[i-2], data[i-1])\n",
    "        count_no_of_newkey = Bi_Probability[Lang][new_key]\n",
    "        \n",
    "        count = count * count_no_of_key / count_no_of_newkey\n",
    "    \n",
    "    return count\n",
    "\n",
    "#Function to calculate ngram model accuracies of the given data_set\n",
    "def Language_Pred_Model(data_set, First_Lang, Sec_Lang):\n",
    "    count_unigrams = 0\n",
    "    count_bigrams = 0\n",
    "    count_trigrams = 0\n",
    "    \n",
    "    for word in data_set:\n",
    "        uni_prob_lang1 = Find_Unigram_Prob(word, First_Lang)\n",
    "        uni_prob_lang2 = Find_Unigram_Prob(word, Sec_Lang)\n",
    "        \n",
    "        bi_prob_lang1 = Find_Bigram_Prob(word, First_Lang)\n",
    "        bi_prob_lang2 = Find_Bigram_Prob(word, Sec_Lang)\n",
    "        \n",
    "        tri_prob_lang1 = Find_Trigram_Prob(word, First_Lang)\n",
    "        tri_prob_lang2 = Find_Trigram_Prob(word, Sec_Lang)\n",
    "    \n",
    "        \n",
    "        if uni_prob_lang1 >= uni_prob_lang2:\n",
    "            count_unigrams = count_unigrams + 1\n",
    "        \n",
    "        if bi_prob_lang1 >= bi_prob_lang2:\n",
    "            count_bigrams = count_bigrams + 1\n",
    "        \n",
    "        \n",
    "        if tri_prob_lang1 >= tri_prob_lang2:\n",
    "            count_trigrams = count_trigrams + 1\n",
    "    \n",
    "    print(\"-----------------------------------------------------------------------\")\n",
    "    print(\"Accuracy for Unigram Model:\", ((count_unigrams * 100) / len(data_set)))\n",
    "    print(\"Accuracy for Bigram Model:\", ((count_bigrams * 100) / len(data_set)))\n",
    "    print(\"Accuracy for Trigram Model:\", ((count_trigrams * 100) / len(data_set)))\n",
    "\n",
    "\n",
    "english = udhr.raw('English-Latin1') \n",
    "french = udhr.raw('French_Francais-Latin1') \n",
    "italian = udhr.raw('Italian_Italiano-Latin1') \n",
    "spanish = udhr.raw('Spanish_Espanol-Latin1')  \n",
    "\n",
    "corpus_data_all = [data_preprocess(lang) for lang in [english, french, italian, spanish]]\n",
    "\n",
    "\n",
    "english = corpus_data_all[0]\n",
    "french = corpus_data_all[1]\n",
    "italian = corpus_data_all[2]\n",
    "spanish = corpus_data_all[3]\n",
    "\n",
    "\n",
    "english_train, english_dev = english[0:1000], english[1000:1100]\n",
    "french_train, french_dev = french[0:1000], french[1000:1100]\n",
    "italian_train, italian_dev = italian[0:1000], italian[1000:1100]\n",
    "spanish_train, spanish_dev = spanish[0:1000], spanish[1000:1100]  \n",
    "english_test = udhr.words('English-Latin1')[0:1000]\n",
    "french_test = udhr.words('French_Francais-Latin1')[0:1000]\n",
    "italian_test = udhr.words('Italian_Italiano-Latin1')[0:1000]\n",
    "spanish_test = udhr.words('Spanish_Espanol-Latin1')[0:1000]\n",
    "\n",
    "#train data for all languages\n",
    "train_data = [english_train,french_train,\n",
    "         italian_train,spanish_train]\n",
    "\n",
    "#development data for all lenguages\n",
    "dev_data = [english_dev,french_dev,\n",
    "       italian_dev,spanish_dev]\n",
    "\n",
    "#test data for all lenguages\n",
    "test_data = [english_test,french_test,\n",
    "        italian_test, spanish_test]\n",
    "\n",
    "#Test data being taken as raw data it needs to be preprocessed before using\n",
    "test_data = [[data_preprocess(word) for word in test_sample] for test_sample in test_data]\n",
    "\n",
    "\n",
    "Unigrams_Train_Data = [ngrams(train_data[language], 1) \n",
    "            for language in Languages_List]\n",
    "\n",
    "Bigrams_Train_Data = [ngrams(train_data[language], 2, \n",
    "                  pad_left=True, pad_right=True, \n",
    "                  left_pad_symbol=' ', right_pad_symbol=' ') \n",
    "            for language in Languages_List]\n",
    "\n",
    "Trigrams_Train_Data = [ngrams(train_data[language], 3, \n",
    "                  pad_left=True, pad_right=True, \n",
    "                  left_pad_symbol=' ', right_pad_symbol=' ') \n",
    "            for language in Languages_List]\n",
    "\n",
    "\n",
    "#Finding Frequency Distribution and Probablities using the calculated Frequency Distribution of Unigrams, Bigrams , Trigrams Calculated \n",
    "Unigram_Freq = [nltk.FreqDist(unigram_data) for unigram_data in Unigrams_Train_Data]\n",
    "Bigram_Freq = [nltk.FreqDist(bigram_data) for bigram_data in Bigrams_Train_Data]\n",
    "Trigram_Freq = [nltk.FreqDist(trigram_data) for trigram_data in Trigrams_Train_Data]\n",
    "Uni_Probability = [find_probablity(freqdist) for freqdist in Unigram_Freq]\n",
    "Bi_Probability = [find_probablity(freqdist) for freqdist in Bigram_Freq]\n",
    "Tri_Probability = [find_probablity(freqdist) for freqdist in Trigram_Freq]\n",
    "\n",
    "\n",
    "print(\"DEV RESULTS:\")\n",
    "print(\"\\n\")\n",
    "print(\"*English-French : \")\n",
    "Language_Pred_Model(dev_data[0].split(), ENGLISH, FRENCH);\n",
    "print(\"\\n\")\n",
    "print(\"*Spanish-Italian : \")\n",
    "Language_Pred_Model(dev_data[1].split(), SPANISH, ITALIAN);\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"************************************************************************\")\n",
    "print(\"\\n\")\n",
    "print(\"TEST OUTPUT:\")\n",
    "print(\"\\n\")\n",
    "print(\"*English-French : \")\n",
    "#Question 1 - Selected and tested model for English and French Languages\n",
    "Language_Pred_Model(test_data[0], ENGLISH, FRENCH);\n",
    "print(\"\\n\")\n",
    "print(\"*Spanish-Italian : \")\n",
    "#Question 2 - Selected and tested model for Spanish and Italian languages\n",
    "Language_Pred_Model(test_data[3], SPANISH, ITALIAN);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Question:\n",
    "Which language pair is harder to distinguish?\n",
    "Calculating the accuracies of the Unigram, Bigram and Trigram models for all the language models it is obseved that the accuracy for the language pair of Spanish - Italian is harder."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
